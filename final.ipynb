{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "421bfb35-571f-4e66-b906-e135d337c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, Input, Conv2D, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1359949-6bd6-40ba-b13e-36fa878ccf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset paths ---\n",
    "DATA_DIR = r\"C:\\Users\\abhis\\Desktop\\SET\\MLPROJECT\\dataset\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "MODEL_PATH = 'backend/model/rcnn_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1246391-f2b5-4291-af20-2b05a40aba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Augmentation ---\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58e0e4a3-e080-478f-92d2-728b2a21eec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6328 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = data_gen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd193569-beb0-4884-b9bd-8227f7492f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1581 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = data_gen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f9a5032-c40c-4737-b7cf-93f91020cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Conv2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_rcnn():\n",
    "    input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Pretrained ResNet50 as feature extractor\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
    "    x = base_model.output\n",
    "\n",
    "    # Region Proposal Network (RPN)\n",
    "    rpn = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    rpn = BatchNormalization()(rpn)  # Added Batch Norm\n",
    "\n",
    "    rpn_cls = Conv2D(9, (1, 1), activation='sigmoid', name='rpn_cls')(rpn)\n",
    "    rpn_reg = Conv2D(36, (1, 1), activation='linear', name='rpn_reg')(rpn)\n",
    "\n",
    "    # ROI Pooling (simplified)\n",
    "    roi_pool = GlobalAveragePooling2D()(rpn)\n",
    "    roi_pool = Dropout(0.5)(roi_pool)  # Added Dropout\n",
    "\n",
    "    # Classification head\n",
    "    classifier = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(roi_pool)\n",
    "    classifier = Dropout(0.5)(classifier)\n",
    "    classifier = Dense(1, activation='sigmoid', name='class_output')(classifier)\n",
    "\n",
    "    # BBox Regression head\n",
    "    bbox_regressor = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(roi_pool)\n",
    "    bbox_regressor = Dense(4, activation='linear', name='bbox_output')(bbox_regressor)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=[classifier, bbox_regressor])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss={\n",
    "            'class_output': 'binary_crossentropy',\n",
    "            'bbox_output': 'mse'\n",
    "        },\n",
    "        metrics={\n",
    "            'class_output': 'accuracy',\n",
    "            'bbox_output': 'mae'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53b92e31-84f8-4e3c-885e-c2919f2ee2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Early Stopping ---\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebc36cbb-b3bf-468c-8fcd-d97c19da9c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "198/198 [==============================] - 2935s 14s/step - loss: 0.8245 - class_output_loss: 0.3498 - bbox_output_loss: 0.2731 - class_output_accuracy: 0.8560 - bbox_output_mae: 0.4075 - val_loss: 2.0172 - val_class_output_loss: 1.0832 - val_bbox_output_loss: 0.7348 - val_class_output_accuracy: 0.6863 - val_bbox_output_mae: 0.6800\n",
      "Epoch 2/20\n",
      "198/198 [==============================] - 2851s 14s/step - loss: 0.5101 - class_output_loss: 0.1875 - bbox_output_loss: 0.1256 - class_output_accuracy: 0.9396 - bbox_output_mae: 0.2736 - val_loss: 1.8488 - val_class_output_loss: 1.2316 - val_bbox_output_loss: 0.4228 - val_class_output_accuracy: 0.6863 - val_bbox_output_mae: 0.4521\n",
      "Epoch 3/20\n",
      "198/198 [==============================] - 2839s 14s/step - loss: 0.4232 - class_output_loss: 0.1434 - bbox_output_loss: 0.0882 - class_output_accuracy: 0.9526 - bbox_output_mae: 0.2244 - val_loss: 1.5349 - val_class_output_loss: 1.0614 - val_bbox_output_loss: 0.2847 - val_class_output_accuracy: 0.6863 - val_bbox_output_mae: 0.3657\n",
      "Epoch 4/20\n",
      "198/198 [==============================] - 2830s 14s/step - loss: 0.3740 - class_output_loss: 0.1181 - bbox_output_loss: 0.0704 - class_output_accuracy: 0.9594 - bbox_output_mae: 0.1977 - val_loss: 2.1769 - val_class_output_loss: 1.7157 - val_bbox_output_loss: 0.2789 - val_class_output_accuracy: 0.6863 - val_bbox_output_mae: 0.3436\n",
      "Epoch 5/20\n",
      "198/198 [==============================] - 2835s 14s/step - loss: 0.3406 - class_output_loss: 0.1025 - bbox_output_loss: 0.0592 - class_output_accuracy: 0.9655 - bbox_output_mae: 0.1790 - val_loss: 1.9923 - val_class_output_loss: 1.5440 - val_bbox_output_loss: 0.2730 - val_class_output_accuracy: 0.6863 - val_bbox_output_mae: 0.3487\n",
      "Epoch 6/20\n",
      "198/198 [==============================] - 2839s 14s/step - loss: 0.3136 - class_output_loss: 0.0916 - bbox_output_loss: 0.0502 - class_output_accuracy: 0.9684 - bbox_output_mae: 0.1631 - val_loss: 1.4662 - val_class_output_loss: 1.0623 - val_bbox_output_loss: 0.2359 - val_class_output_accuracy: 0.7293 - val_bbox_output_mae: 0.2948\n",
      "Epoch 7/20\n",
      "198/198 [==============================] - 2843s 14s/step - loss: 0.2928 - class_output_loss: 0.0834 - bbox_output_loss: 0.0452 - class_output_accuracy: 0.9728 - bbox_output_mae: 0.1513 - val_loss: 1.5668 - val_class_output_loss: 1.1954 - val_bbox_output_loss: 0.2110 - val_class_output_accuracy: 0.7147 - val_bbox_output_mae: 0.3267\n",
      "Epoch 8/20\n",
      "198/198 [==============================] - 2838s 14s/step - loss: 0.2688 - class_output_loss: 0.0742 - bbox_output_loss: 0.0381 - class_output_accuracy: 0.9741 - bbox_output_mae: 0.1364 - val_loss: 0.9927 - val_class_output_loss: 0.6594 - val_bbox_output_loss: 0.1808 - val_class_output_accuracy: 0.7546 - val_bbox_output_mae: 0.2821\n",
      "Epoch 9/20\n",
      "198/198 [==============================] - 2838s 14s/step - loss: 0.2559 - class_output_loss: 0.0706 - bbox_output_loss: 0.0367 - class_output_accuracy: 0.9768 - bbox_output_mae: 0.1332 - val_loss: 0.9814 - val_class_output_loss: 0.6679 - val_bbox_output_loss: 0.1689 - val_class_output_accuracy: 0.7748 - val_bbox_output_mae: 0.2743\n",
      "Epoch 10/20\n",
      "198/198 [==============================] - 2833s 14s/step - loss: 0.2366 - class_output_loss: 0.0643 - bbox_output_loss: 0.0316 - class_output_accuracy: 0.9791 - bbox_output_mae: 0.1207 - val_loss: 0.8919 - val_class_output_loss: 0.6290 - val_bbox_output_loss: 0.1262 - val_class_output_accuracy: 0.8444 - val_bbox_output_mae: 0.1837\n",
      "Epoch 11/20\n",
      "198/198 [==============================] - 2857s 14s/step - loss: 0.2190 - class_output_loss: 0.0582 - bbox_output_loss: 0.0281 - class_output_accuracy: 0.9807 - bbox_output_mae: 0.1123 - val_loss: 1.1584 - val_class_output_loss: 0.8142 - val_bbox_output_loss: 0.2155 - val_class_output_accuracy: 0.7261 - val_bbox_output_mae: 0.3201\n",
      "Epoch 12/20\n",
      "198/198 [==============================] - 2859s 14s/step - loss: 0.2188 - class_output_loss: 0.0655 - bbox_output_loss: 0.0285 - class_output_accuracy: 0.9758 - bbox_output_mae: 0.1093 - val_loss: 1.0368 - val_class_output_loss: 0.7248 - val_bbox_output_loss: 0.1911 - val_class_output_accuracy: 0.7685 - val_bbox_output_mae: 0.2849\n",
      "Epoch 13/20\n",
      "198/198 [==============================] - 2870s 14s/step - loss: 0.2039 - class_output_loss: 0.0605 - bbox_output_loss: 0.0264 - class_output_accuracy: 0.9785 - bbox_output_mae: 0.1036 - val_loss: 1.3199 - val_class_output_loss: 1.0089 - val_bbox_output_loss: 0.1977 - val_class_output_accuracy: 0.7691 - val_bbox_output_mae: 0.2545\n",
      "Epoch 14/20\n",
      "198/198 [==============================] - 2308s 12s/step - loss: 0.1677 - class_output_loss: 0.0384 - bbox_output_loss: 0.0197 - class_output_accuracy: 0.9880 - bbox_output_mae: 0.0914 - val_loss: 2.0499 - val_class_output_loss: 1.6925 - val_bbox_output_loss: 0.2514 - val_class_output_accuracy: 0.7154 - val_bbox_output_mae: 0.3031\n",
      "Epoch 15/20\n",
      "198/198 [==============================] - 2869s 14s/step - loss: 0.1686 - class_output_loss: 0.0464 - bbox_output_loss: 0.0199 - class_output_accuracy: 0.9842 - bbox_output_mae: 0.0882 - val_loss: 1.2386 - val_class_output_loss: 0.9642 - val_bbox_output_loss: 0.1757 - val_class_output_accuracy: 0.7812 - val_bbox_output_mae: 0.2389\n"
     ]
    }
   ],
   "source": [
    "# --- Train the Model ---\n",
    "model = build_rcnn()\n",
    "early_stopping = EarlyStopping(monitor='val_class_output_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_class_output_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43428f5e-fd26-48c7-a20b-775f9e6abca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at backend/model/rcnn_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save('backend/model/rcnn_model_3rd.h5') \n",
    "print(f\"Model saved at {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
